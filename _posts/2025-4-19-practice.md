---
layout: post
title: "0åŸºç¡€AIé¡¹ç›®å®è·µå…¥é—¨"
date:   2025-04-19
tags: [lecture]
comments: true
author: MilleXi
--- 
ç¬”è€…åœ¨å­¦æ ¡AIç¤¾å›¢å†…åˆšä¸¾åŠå®ŒCVé¡¹ç›®å®è·µèµ›ï¼Œsoç»„ç»‡äº†ä¸€æ¬¡è®²åº§ï¼Œä¾›æ›´å¤šçš„0åŸºç¡€åŒå­¦å…¥é—¨ï¼Œä¸€èµ·è·Ÿéšç¬”è€…çš„è„šæ­¥~ä½¿ç”¨CNNå’ŒResNet18å®Œæˆä¸€ä¸ªå›¾åƒäºŒåˆ†ç±»ä»»åŠ¡å§ï¼
<!-- more -->

## ä¸€ã€è®²åº§æ€»è§ˆ

### è®²åº§ç›®æ ‡

æœ¬è®²åº§æ—¨åœ¨ä¸º0åŸºç¡€AIå®è·µåŒå­¦æä¾›ä¸€æ¬¡å®Œæ•´çš„è®¡ç®—æœºè§†è§‰å¼€æºé¡¹ç›®çš„å…¥é—¨ä½“éªŒã€‚é€šè¿‡PyTorchå®ç°ä¸€ä¸ªå›¾åƒäºŒåˆ†ç±»ç³»ç»Ÿï¼ŒåŒ…æ‹¬ï¼š

- æ„å»ºä¸€ä¸ªç®€å•CNNæ¨¡å‹
- ä½¿ç”¨é¢„è®­ç»ƒResNet18è¿›è¡Œè¿ç§»å­¦ä¹ 
- å®Œæˆæ•°æ®åŠ è½½ã€æ¨¡å‹è®­ç»ƒã€æµ‹è¯•è¯„ä¼°ä¸å¯è§†åŒ–å…¨è¿‡ç¨‹

æœ€ç»ˆç›®æ ‡ï¼š**ä½¿ç”¨GitHubæ‰˜ç®¡é¡¹ç›®ï¼ŒæŒæ¡AIé¡¹ç›®æ ‡å‡†å¼€å‘æµç¨‹**

---

## äºŒã€ä»€ä¹ˆæ˜¯ GitHubï¼Ÿ

> GitHub æ˜¯ä¸€ä¸ªé¢å‘å¼€å‘è€…çš„ä»£ç æ‰˜ç®¡å¹³å°ï¼Œå®ƒå…è®¸ä½ å°†è‡ªå·±çš„ä»£ç ä¸Šä¼ åˆ°äº‘ç«¯ï¼Œå¹¶å’Œä»–äººåä½œå¼€å‘é¡¹ç›®ã€‚å®ƒæ˜¯å¼€æºè½¯ä»¶å’ŒAIé¡¹ç›®æœ€å¸¸ç”¨çš„â€œé›†ä½“ä»“åº“â€ã€‚
> 

### æ ¸å¿ƒå…³é”®è¯

| åè¯ | å«ä¹‰ |
| --- | --- |
| `Repository`ï¼ˆä»“åº“ï¼‰ | é¡¹ç›®çš„å­˜å‚¨ç©ºé—´ï¼ˆä»£ç  + æ–‡æ¡£ + ç‰ˆæœ¬å†å²ï¼‰ |
| `Commit`ï¼ˆæäº¤ï¼‰ | å°†æ”¹åŠ¨ä¿å­˜åˆ°ç‰ˆæœ¬å†å²ä¸­ |
| `Push`ï¼ˆæ¨é€ï¼‰ | æŠŠæœ¬åœ°ä»£ç æäº¤ä¸Šä¼ åˆ°GitHub |
| `Pull Request`ï¼ˆPRï¼‰ | è¯·æ±‚åˆå¹¶ä»£ç ï¼ˆé€‚ç”¨äºåä½œï¼‰ |
| `Issues`ï¼ˆé—®é¢˜è¿½è¸ªï¼‰ | é¡¹ç›®çš„åé¦ˆç³»ç»Ÿ |
| `README.md` | é¡¹ç›®ä¸»é¡µè¯´æ˜æ–‡æ¡£ |
| `LICENSE` | é¡¹ç›®çš„å¼€æºåè®® |

> ç±»æ¯”ï¼šä½ å¯ä»¥æŠŠ GitHub æƒ³è±¡æˆâ€œä»£ç çš„ç½‘ç›˜+ç‰ˆæœ¬ç®¡ç†+åä½œå¹³å°â€ã€‚
> 

---

### ä»€ä¹ˆæ˜¯å¼€æºï¼Ÿä¸ºä»€ä¹ˆè¦å¼€æºï¼Ÿ

**å¼€æºï¼ˆOpen Sourceï¼‰** æŒ‡çš„æ˜¯å¼€å‘è€…å°†è½¯ä»¶æºä»£ç å…¬å¼€ï¼Œå…è®¸ä»»ä½•äººæŸ¥çœ‹ã€å­¦ä¹ ã€ä¿®æ”¹å’Œåˆ†å‘è¿™äº›ä»£ç ã€‚

å¼€æºä¸æ˜¯â€œå…è´¹ä½¿ç”¨â€é‚£ä¹ˆç®€å•ï¼Œè€Œæ˜¯ä¸€å¥—**åŸºäºè®¸å¯åè®®çš„å…±äº«ä¸åä½œæœºåˆ¶**ã€‚

**å¼€æºçš„å¥½å¤„ï¼š**

- å¯ä»¥å­¦ä¹ ä»–äººçš„é¡¹ç›®ç»“æ„ä¸æŠ€æœ¯å®ç°
- èƒ½å¿«é€Ÿæ„å»ºå±äºè‡ªå·±çš„æ¨¡å‹ã€å¹³å°
- æ–¹ä¾¿å›¢é˜Ÿåä½œä¸ä»£ç ç‰ˆæœ¬ç®¡ç†
- æœ‰æœºä¼šè·å¾—è´¡çŒ®è®°å½•ï¼ˆcontributionï¼‰ï¼Œä¸°å¯Œå±¥å†

---

### å¸¸è§å¼€æºè®¸å¯è¯ï¼ˆLicenseï¼‰ä»‹ç»

å¼€æº â‰  æ²¡æœ‰ç‰ˆæƒï¼**å¿…é¡»é™„å¸¦è®¸å¯è¯æ‰æ˜¯åˆæ³•å¼€æº**

ä»¥ä¸‹æ˜¯æœ€å¸¸ç”¨çš„å‡ ç§ï¼š

| License | æ˜¯å¦å¯å•†ç”¨ | æ˜¯å¦å…è®¸ä¿®æ”¹ | æ˜¯å¦éœ€æ³¨æ˜åŸä½œè€… | æ˜¯å¦éœ€å¼€æºä¿®æ”¹å†…å®¹ |
| --- | --- | --- | --- | --- |
| **MIT**ï¼ˆæ¨èï¼‰ | âœ… | âœ… | âœ… | âŒ |
| **Apache 2.0** | âœ… | âœ… | âœ… | âŒï¼ˆä½†éœ€å£°æ˜ä¿®æ”¹ï¼‰ |
| **GPL v3** | âœ… | âœ… | âœ… | âœ… |
| **BSD 3-Clause** | âœ… | âœ… | âœ… | âŒ |

> ä¸€èˆ¬æ•™å­¦é¡¹ç›®ã€ä¸ªäººé¡¹ç›®æ¨èä½¿ç”¨ MIT License â€”â€” ç®€æ´ã€å®½æ¾ã€æ˜“ç”¨ã€‚
> 

---

### ä»€ä¹ˆæ˜¯ READMEï¼Ÿå®ƒæ˜¯ç”¨æ¥å¹²ä»€ä¹ˆçš„ï¼Ÿ

`README.md` æ˜¯ GitHub ä¸Šæ¯ä¸€ä¸ªé¡¹ç›®ä»“åº“çš„â€œé¦–é¡µè¯´æ˜æ–‡ä»¶â€ï¼Œå½“åˆ«äººç‚¹è¿›ä½ çš„ä»“åº“æ—¶ï¼Œæœ€å…ˆçœ‹åˆ°çš„å°±æ˜¯å®ƒã€‚å®ƒå°±åƒæ˜¯ä½ é¡¹ç›®çš„â€œåç‰‡â€å’Œâ€œä½¿ç”¨æ‰‹å†Œâ€ã€‚

**å®ƒä¸»è¦ç”¨æ¥å‘Šè¯‰åˆ«äººï¼š**

| å†…å®¹ | ä¸¾ä¾‹ |
| --- | --- |
| ğŸ” **é¡¹ç›®æ˜¯ä»€ä¹ˆ** | â€œè¿™æ˜¯ä¸€ä¸ªä½¿ç”¨PyTorchå®ç°å›¾åƒåˆ†ç±»çš„å…¥é—¨é¡¹ç›®â€ |
| ğŸ› ï¸ **æ€ä¹ˆå®‰è£…** | â€œä½¿ç”¨ pip install -r requirements.txt å®‰è£…ä¾èµ–â€ |
| ğŸš€ **æ€ä¹ˆè¿è¡Œ** | â€œè¿è¡Œ python train.py å¯åŠ¨è®­ç»ƒâ€ |
| ğŸ“‚ **é¡¹ç›®ç»“æ„** | â€œmodels/ æ”¾æ¨¡å‹ä»£ç ï¼Œdataset/ æ˜¯æ•°æ®é›†å¤„ç†â€ |
| ğŸ§  **ç”¨åˆ°äº†å“ªäº›æŠ€æœ¯** | â€œä½¿ç”¨äº† ResNet18ã€è¿ç§»å­¦ä¹ ã€æ•°æ®å¢å¼ºç­‰â€ |
| ğŸ“Š **æœ€ç»ˆæ•ˆæœ / Demo æˆªå›¾** | â€œæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¾¾åˆ°92%çš„å‡†ç¡®ç‡â€ |
| ğŸ“„ **å‚è€ƒèµ„æ–™** | â€œå‚è€ƒè®ºæ–‡ã€å¼€æºåº“é“¾æ¥â€ |
| ğŸ‘©â€ğŸ’» **å¼€å‘è€…ä¿¡æ¯** | â€œä½œè€…ï¼šYourNameï¼Œæ¬¢è¿PRæˆ–æIssueâ€ |

### ä»€ä¹ˆæ˜¯ .gitignoreï¼Ÿ

> .gitignore æ˜¯ä¸€ä¸ª å‘Šè¯‰ Git å“ªäº›æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ä¸åº”è¯¥è¢«åŠ å…¥ç‰ˆæœ¬æ§åˆ¶ï¼ˆå³ä¸è¢«æäº¤åˆ°ä»“åº“ï¼‰ çš„é…ç½®æ–‡ä»¶ã€‚
> 

æ¢å¥è¯è¯´ï¼š

> âœ… Git ä¼šå¿½ç•¥ .gitignore ä¸­åˆ—å‡ºçš„å†…å®¹ï¼Œä¸ä¼šè¿½è¸ªå®ƒä»¬çš„å˜æ›´ï¼Œä¹Ÿä¸ä¼šå‡ºç°åœ¨ git add . ä¹‹åçš„æäº¤åˆ—è¡¨é‡Œã€‚
> 

ä¸ºä»€ä¹ˆéœ€è¦ `.gitignore`ï¼Ÿ

å› ä¸ºå¾ˆå¤šæ–‡ä»¶**æ˜¯ä¸´æ—¶ç”Ÿæˆã€æ•æ„Ÿæˆ–è€…æœºå™¨ç‰¹å®šçš„**ï¼Œä¸é€‚åˆæäº¤åˆ° Git ä»“åº“ï¼Œæ¯”å¦‚ï¼š

| ç±»å‹ | ç¤ºä¾‹ |
| --- | --- |
| Python ç¼“å­˜æ–‡ä»¶ | `__pycache__/`, `*.pyc` |
| è™šæ‹Ÿç¯å¢ƒ | `venv/`, `.env/` |
| æ¨¡å‹æ–‡ä»¶ | `*.pth`, `*.pt`, `checkpoints/` |
| æ—¥å¿—ä¸è¾“å‡º | `*.log`, `*.csv`, `*.png` |
| Jupyter è‡ªåŠ¨æ£€æŸ¥ç‚¹ | `.ipynb_checkpoints/` |
| æœ¬åœ°é…ç½®æ–‡ä»¶ | `.vscode/`, `.idea/` |
| æ•°æ®æ–‡ä»¶ | `data/`, `*.zip`, `*.h5` |

`.gitignore` æ˜¯ Git ç”¨æ¥**æ’é™¤é‚£äº›ä½ ä¸æƒ³æäº¤çš„æ–‡ä»¶**çš„æ–‡ä»¶ï¼Œå®ƒè®©ä½ çš„ä»£ç ä»“åº“æ›´å¹²å‡€ã€æ›´ä¸“ä¸šã€æ›´å®‰å…¨ã€‚

---

### é¡¹ç›®æ–‡ä»¶ç»“æ„è¯¦è§£

```
cv-demo/
â”œâ”€â”€ data/                   # æ•°æ®é›†
â”œâ”€â”€ dataset/                # æ•°æ®é›†åŠ è½½æ¨¡å—
â”‚   â””â”€â”€ dataset.py          # åŒ…å«è‡ªå®šä¹‰ Dataset ç±»
â”œâ”€â”€ models/                 # æ¨¡å‹å®šä¹‰æ¨¡å—
â”‚   â”œâ”€â”€ cnn.py              # ç®€å• CNN æ¨¡å‹ç»“æ„
â”‚   â””â”€â”€ resnet.py           # åŠ è½½ä¸ä¿®æ”¹ ResNet18 æ¨¡å‹
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml         # é¡¹ç›®é…ç½®æ–‡ä»¶ï¼ˆæ¨¡å‹ã€ä¼˜åŒ–å™¨ã€å­¦ä¹ ç‡ç­‰å‚æ•°ï¼‰
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ visualizer.py       # ç»˜åˆ¶ loss/acc æ›²çº¿æˆ–æ··æ·†çŸ©é˜µ
â”‚   â””â”€â”€ helpers.py          # å¦‚early stopã€æ—¥å¿—è®°å½•ç­‰
â”œâ”€â”€ train.py                # è®­ç»ƒä¸»æµç¨‹ï¼Œå°è£…è®­ç»ƒé€»è¾‘
â”œâ”€â”€ evaluate.py             # è¯„ä¼°æ¨¡å‹æ€§èƒ½å¹¶æ‰“å°å‡†ç¡®ç‡
â”œâ”€â”€ main.py                 # å¯é€‰å…¥å£ï¼ˆå°è£…trainå’Œevalï¼‰
â”œâ”€â”€ requirements.txt        # pipä¾èµ–æ–‡ä»¶ï¼Œæ¨èä½¿ç”¨ pipreqs è‡ªåŠ¨ç”Ÿæˆ
â”œâ”€â”€ README.md               # é¡¹ç›®è¯´æ˜æ–‡ä»¶ï¼Œè§„èŒƒå†™æ³•
â””â”€â”€ .gitignore              # å¿½ç•¥ __pycache__/ã€.DS_Storeã€.ipynb_checkpoints ç­‰
```

---

## ä¸‰ã€dog vs. cat äºŒåˆ†ç±»å®ä¾‹

### `dataset.py` - æ•°æ®åŠ è½½æ¨¡å—

```python
import os
from PIL import Image
from torch.utils.data import Dataset
from torchvision import transforms

class CatDogDataset(Dataset):
    """
    è‡ªå®šä¹‰çš„çŒ«ç‹—äºŒåˆ†ç±»æ•°æ®é›†ï¼Œç»§æ‰¿è‡ª PyTorch çš„ Dataset ç±»ã€‚
    æ”¯æŒè®­ç»ƒä¸æµ‹è¯•æ¨¡å¼ï¼Œè‡ªåŠ¨è¯»å–å›¾åƒè·¯å¾„å¹¶ç”Ÿæˆæ ‡ç­¾ã€‚

    Args:
        root_dir (str): æ•°æ®é›†æ ¹ç›®å½•ï¼Œæ¯”å¦‚ 'data/train' æˆ– 'data/test'
        transform (callable, optional): æ•°æ®å¢å¼ºä¸é¢„å¤„ç†æ“ä½œ
    """

    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir              # å­˜å‚¨ train æˆ– test è·¯å¾„
        self.transform = transform            # å›¾åƒé¢„å¤„ç† transform

        # label æ˜ å°„ï¼šçŒ«ä¸º 0ï¼Œç‹—ä¸º 1
        self.label_map = {'cat': 0, 'dog': 1}

        self.image_paths = []                 # ä¿å­˜æ‰€æœ‰å›¾åƒçš„è·¯å¾„
        self.labels = []                      # ä¿å­˜å¯¹åº”æ ‡ç­¾

        # éå†æ¯ä¸ªç±»åˆ«æ–‡ä»¶å¤¹
        for label_name in ['cat', 'dog']:
            class_dir = os.path.join(root_dir, label_name)
            for filename in os.listdir(class_dir):
                if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
                    self.image_paths.append(os.path.join(class_dir, filename))
                    self.labels.append(self.label_map[label_name])

    def __len__(self):
        """è¿”å›æ•°æ®é›†å¤§å°"""
        return len(self.image_paths)

    def __getitem__(self, idx):
        """
        æ ¹æ®ç´¢å¼• idx è¿”å›ä¸€ä¸ªæ ·æœ¬ï¼ˆå›¾åƒ, æ ‡ç­¾ï¼‰
        """
        img_path = self.image_paths[idx]
        label = self.labels[idx]

        # æ‰“å¼€å›¾åƒ
        image = Image.open(img_path).convert('RGB')  # ä¿è¯ç»Ÿä¸€ä¸º RGB æ ¼å¼

        # åº”ç”¨é¢„å¤„ç†/å¢å¼º
        if self.transform:
            image = self.transform(image)

        return image, label
```

å…¶ä¸­ä¸‰ä¸ªå‡½æ•°æ˜¯ PyTorch ä¸­æ„å»ºè‡ªå®šä¹‰æ•°æ®é›† `Dataset` ç±»æ—¶å¿…é¡»å®ç°çš„ä¸‰ä¸ª**æ ¸å¿ƒé­”æ³•æ–¹æ³•**ã€‚ä½ å¯ä»¥æŠŠå®ƒä»¬çœ‹ä½œæ˜¯â€œå‘Šè¯‰ PyTorch æ€ä¹ˆç®¡ç†ã€è®¿é—®ä½ è‡ªå®šä¹‰çš„æ•°æ®â€ã€‚

1. `__init__(self, ...)` â€”â€” åˆå§‹åŒ–æ–¹æ³•ï¼ˆè£…è½½æ•°æ®çš„å…¥å£ï¼‰
    
    **ä½œç”¨ï¼š**
    
    - è®¾ç½®æ•°æ®é›†çš„â€œå…¨å±€å˜é‡â€ï¼ˆå¦‚å›¾åƒè·¯å¾„ã€æ ‡ç­¾ã€transformï¼‰
    - åœ¨è¿™é‡Œåšæ•°æ®è·¯å¾„æ”¶é›†ã€æ ‡ç­¾ç¼–ç ç­‰å‡†å¤‡å·¥ä½œ
    
    **æ³¨æ„ï¼š**
    
    - `self.image_paths` å­˜è·¯å¾„
    - `self.labels` å­˜æ•°å­—æ ‡ç­¾
    - `transform` æ˜¯å…³é”®æ¨¡å—ï¼Œç”¨æ¥æ§åˆ¶é¢„å¤„ç†

2.  `__len__(self)` â€”â€” è¿”å›æ•°æ®é›†å¤§å°ï¼ˆé•¿åº¦ï¼‰

**ä½œç”¨ï¼š**

- å‘Šè¯‰ `DataLoader` æ€»å…±æœ‰å¤šå°‘ä¸ªæ ·æœ¬

**æ³¨æ„ï¼š**

- PyTorch è®­ç»ƒè¿‡ç¨‹ä¸­ä¼š `for i in range(len(dataset))` æ¥ç´¢å¼•æ•°æ®
- å†™æ³•æ°¸è¿œæ˜¯ï¼š`return len(self.image_paths)`
1.  `__getitem__(self, idx)` â€”â€” æ ¹æ®ç´¢å¼•è¿”å›ç¬¬ idx ä¸ªæ ·æœ¬
    
    **ä½œç”¨ï¼š**
    
    - è¿”å›ä¸€å¯¹ `(image_tensor, label)`ï¼Œä¹Ÿå°±æ˜¯æ¨¡å‹è®­ç»ƒçš„â€œä¸€ä¸ªæ ·æœ¬â€
    - **idx** æ˜¯ä¸‹æ ‡ï¼Œç”± DataLoader è‡ªåŠ¨ä¼ å…¥
    
    **æ³¨æ„ï¼š**
    
    - è¦å°†å›¾åƒè¯»å–ã€è½¬æ¢ï¼ˆtransformï¼‰åœ¨è¿™é‡Œå®Œæˆ
    - æ¯æ¬¡è°ƒç”¨ `__getitem__`ï¼Œç­‰äºâ€œæŠ½å‡ºä¸€ä¸ªæ ·æœ¬äº¤ç»™æ¨¡å‹è®­ç»ƒâ€
    - æœ€ç»ˆè¿”å›çš„æ˜¯æ¨¡å‹éœ€è¦çš„ `(X, y)`ï¼šå›¾åƒå¼ é‡ + æ•°å­—æ ‡ç­¾

**æ€»ç»“å£è¯€**

```
__init__ï¼šå‡†å¤‡æ•°æ®è¡¨ï¼ˆæ”¶é›†è·¯å¾„å’Œæ ‡ç­¾ï¼‰
__len__ ï¼šå‘Šè¯‰æ€»å…±æœ‰å‡ æ¡æ•°æ®
__getitem__ï¼šæ¯æ¬¡æŒ‰ç¼–å·å–å‡ºä¸€æ¡ï¼ˆè¿”å›å›¾åƒ + æ ‡ç­¾ï¼‰
```

---

### `model.py` - è‡ªå®šä¹‰CNNæ¨¡å‹

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class SimpleCNN(nn.Module):
    """
    ä¸€ä¸ªç”¨äºå›¾åƒäºŒåˆ†ç±»çš„ç®€å•å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æ¨¡å‹ã€‚
    ç»“æ„ï¼šConv + ReLU + Pooling x3 + FC x2
    è¾“å…¥å›¾åƒé»˜è®¤å°ºå¯¸ä¸º 3x224x224
    """

    def __init__(self, num_classes=2):
        """
        åˆå§‹åŒ–æ¨¡å‹ç»“æ„

        Args:
            num_classes (int): è¾“å‡ºç±»åˆ«æ•°ï¼Œé»˜è®¤æ˜¯2ï¼ˆcat, dogï¼‰
        """
        super(SimpleCNN, self).__init__()

        # å·ç§¯å±‚1ï¼šè¾“å…¥é€šé“3ï¼Œè¾“å‡ºé€šé“16ï¼Œæ ¸3x3
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)
        # å·ç§¯å±‚2
        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)
        # å·ç§¯å±‚3
        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)

        # æœ€å¤§æ± åŒ–å±‚
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)

        # å…¨è¿æ¥å±‚1ï¼š64ä¸ªé€šé“ï¼Œå›¾åƒç¼©å°3æ¬¡ => 224 -> 112 -> 56 -> 28 -> flatten: 64 * 28 * 28
        self.fc1 = nn.Linear(64 * 28 * 28, 128)
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        """
        å®šä¹‰å‰å‘ä¼ æ’­æµç¨‹

        Args:
            x (Tensor): è¾“å…¥å›¾åƒå¼ é‡ï¼Œå½¢çŠ¶ä¸º (N, 3, 224, 224)

        Returns:
            Tensor: è¾“å‡ºåˆ†ç±» logitsï¼Œå½¢çŠ¶ä¸º (N, num_classes)
        """
        x = self.pool(F.relu(self.conv1(x)))  # -> (N, 16, 112, 112)
        x = self.pool(F.relu(self.conv2(x)))  # -> (N, 32, 56, 56)
        x = self.pool(F.relu(self.conv3(x)))  # -> (N, 64, 28, 28)

        x = x.view(x.size(0), -1)  # å±•å¹³ä¸ºå‘é‡

        x = F.relu(self.fc1(x))    # -> (N, 128)
        x = self.fc2(x)            # -> (N, num_classes)

        return x
```

**`torch.nn` æ˜¯ PyTorch æä¾›çš„ä¸€ä¸ªç¥ç»ç½‘ç»œæ„å»ºæ¨¡å—åº“ï¼ŒåŒ…å«äº†ä½ æ­å»ºç¥ç»ç½‘ç»œæ‰€éœ€çš„æ‰€æœ‰â€œç§¯æœ¨å—â€** â€”â€” æ¯”å¦‚ï¼š`Linear`ï¼ˆå…¨è¿æ¥å±‚ï¼‰ã€`Conv2d`ï¼ˆå·ç§¯å±‚ï¼‰ã€`ReLU`ï¼ˆæ¿€æ´»å‡½æ•°ï¼‰ã€`Losså‡½æ•°`ã€`BatchNorm`ã€`Dropout`ï¼Œè¿˜æœ‰æœ€å…³é”®çš„ `nn.Module` ç±»ï¼ï¼ˆæ‰€æœ‰æ¨¡å‹çš„åŸºç±»ï¼Œä½ è¦å†™è‡ªå®šä¹‰æ¨¡å‹å°±ç»§æ‰¿å®ƒï¼‰

**æ¨¡å‹ç»“æ„æ€»è§ˆ**

```
Input: (3, 224, 224)

1. Conv2d(3, 16, kernel_size=3, padding=1) â†’ ReLU â†’ MaxPool2d(2, 2)
â†’ Output shape: (16, 112, 112)

2. Conv2d(16, 32, kernel_size=3, padding=1) â†’ ReLU â†’ MaxPool2d(2, 2)
â†’ Output shape: (32, 56, 56)

3. Conv2d(32, 64, kernel_size=3, padding=1) â†’ ReLU â†’ MaxPool2d(2, 2)
â†’ Output shape: (64, 28, 28)

Flatten â†’ FC(64*28*28, 128) â†’ ReLU â†’ FC(128, 2)
```

**å„å±‚è¯¦ç»†è§£é‡Š**

1. å·ç§¯å±‚ `Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)`
    - **ä¸ºä»€ä¹ˆ in_channels=3**ï¼šå›¾åƒæ˜¯ RGB ä¸‰é€šé“çš„ã€‚
    - **ä¸ºä»€ä¹ˆ out_channels=16**ï¼šè¾“å‡º 16 ä¸ªç‰¹å¾å›¾ï¼ˆfeature mapsï¼‰ï¼Œè®©ç½‘ç»œèƒ½å­¦åˆ°æ¯”åŸå›¾æ›´æŠ½è±¡çš„ç‰¹å¾ã€‚ç¬¬ä¸€å±‚é€šå¸¸ä¸è®¾å¤ªå¤šé€šé“ï¼Œè®¡ç®—é‡ä¼šå¤ªå¤§ã€‚
    - **ä¸ºä»€ä¹ˆ kernel_size=3**ï¼š3x3 æ˜¯ç°ä»£ CNN çš„ç»å…¸å·ç§¯æ ¸å°ºå¯¸ï¼Œèƒ½è¾ƒå¥½åœ°å¹³è¡¡å±€éƒ¨æ„Ÿå—é‡å’Œè®¡ç®—æ•ˆç‡ã€‚
    - **ä¸ºä»€ä¹ˆ padding=1**ï¼šä¸ºä¿è¯è¾“å‡ºå°ºå¯¸ä¸å˜ï¼ˆ224x224ï¼‰ï¼Œä½¿ç”¨ padding=1ï¼ˆå› ä¸º3x3å·ç§¯ä¼šç¼©å°1åœˆï¼‰ã€‚
2. æ¿€æ´»å‡½æ•° `ReLU`
    - **ä¸ºä»€ä¹ˆç”¨ ReLU è€Œä¸æ˜¯ Sigmoid/Tanhï¼Ÿ**
        - è®¡ç®—ç®€å•ï¼ˆåªä¿ç•™æ­£æ•°ï¼‰ï¼›
        - é¿å…æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼›
        - å®è·µè¯æ˜æ•ˆæœéå¸¸å¥½ï¼Œæ˜¯CNNé»˜è®¤æ¿€æ´»å‡½æ•°ã€‚
3. æ± åŒ–å±‚ `MaxPool2d(kernel_size=2, stride=2)`
    - **åŠŸèƒ½**ï¼šå°†ç‰¹å¾å›¾å°ºå¯¸å‡åŠï¼ŒåŒæ—¶ä¿ç•™å±€éƒ¨æœ€å¤§å€¼ï¼Œæé«˜æ¨¡å‹å¯¹å¹³ç§»ã€å™ªå£°çš„é²æ£’æ€§ã€‚
    - **ä¸ºä»€ä¹ˆå°ºå¯¸å‡åŠï¼Ÿ**
        - é™ä½è®¡ç®—é‡ï¼›
        - æé«˜æ„Ÿå—é‡ï¼›
        - é˜²æ­¢è¿‡æ‹Ÿåˆã€‚
4. ç¬¬äºŒã€ä¸‰å±‚å·ç§¯ï¼ˆ`Conv2d(16â†’32â†’64)`ï¼‰
    - **ä¸ºä»€ä¹ˆä¸æ–­åŠ é€šé“æ•°ï¼Ÿ**
        - å›¾åƒè¶Šæ·±ï¼Œç‰¹å¾è¶ŠæŠ½è±¡ï¼Œéœ€è¦æ›´å¤šçš„é€šé“æ¥è¡¨ç¤ºä¸°å¯Œçš„æ¨¡å¼ï¼›
        - ä¸€èˆ¬é‡‡ç”¨ã€Œä½é€šé“ â†’ é«˜é€šé“ã€çš„è®¾è®¡ç­–ç•¥ã€‚
    - **ä¸ºä»€ä¹ˆéƒ½ä¿æŒ kernel=3, padding=1ï¼Ÿ**
        - ä¿æŒä¸€è‡´æ€§ï¼Œé¿å…å›¾åƒå¤ªå¿«ç¼©å°ï¼›
        - èƒ½æ•æ‰æ›´ä¸°å¯Œçš„ç©ºé—´ç»†èŠ‚ã€‚
    
    | å±‚æ¬¡ | æ“ä½œ | è¾“å‡ºå¤§å°è®¡ç®— | è¾“å‡ºå°ºå¯¸ |
    | --- | --- | --- | --- |
    | Conv1 + Pool | Conv2d(3â†’16, kernel=3, padding=1) + MaxPool2d(2,2) | `224 â†’ 224 â†’ 112` | (16, 112, 112) |
    | Conv2 + Pool | Conv2d(16â†’32, kernel=3, padding=1) + MaxPool2d(2,2) | `112 â†’ 112 â†’ 56` | (32, 56, 56) |
    | Conv3 + Pool | Conv2d(32â†’64, kernel=3, padding=1) + MaxPool2d(2,2) | `56 â†’ 56 â†’ 28` | (64, 28, 28) |
    
    é‡ç‚¹ï¼š
    
    - `Conv2d` ä½¿ç”¨äº† `padding=1`ã€`kernel_size=3`ï¼Œ**ä¸ä¼šæ”¹å˜ç‰¹å¾å›¾å°ºå¯¸**ï¼›
    - `MaxPool2d(kernel_size=2, stride=2)` ä¼šå°†å°ºå¯¸ **å‡åŠ**ã€‚
5. å±•å¹³ `x.view(x.size(0), -1)`
    - æŠŠ `(batch_size, 64, 28, 28)` çš„ 4D å¼ é‡å˜ä¸ºäºŒç»´ `(batch_size, 64*28*28)`ï¼Œä»¥ä¾›å…¨è¿æ¥å±‚å¤„ç†ã€‚
6. å…¨è¿æ¥å±‚ `Linear(64*28*28, 128)`
    - **ä¸ºä»€ä¹ˆ128ï¼Ÿ**
        - èµ·åˆ°â€œå‹ç¼©ç‰¹å¾è¡¨ç¤ºâ€çš„ä½œç”¨ï¼ŒåŒæ—¶ä¿ç•™è¾ƒå¼ºçš„è¡¨è¾¾èƒ½åŠ›ï¼›
        - ä¸è®¾å¤ªé«˜ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼›
        - å¯æ ¹æ®è®­ç»ƒæ•ˆæœè°ƒèŠ‚ã€‚

7.è¾“å‡ºå±‚ `Linear(128, 2)`

- **è¾“å‡ºä¸º2ä¸ªç¥ç»å…ƒ**ï¼Œåˆ†åˆ«å¯¹åº”äºŒåˆ†ç±»çš„ä¸¤ä¸ªç±»åˆ«ï¼ˆ`cat=0`, `dog=1`ï¼‰ï¼›
- **è¾“å‡ºé€šå¸¸æ˜¯ raw logits**ï¼Œä½ å¯ä»¥é…åˆ `nn.CrossEntropyLoss()` ä¸€èµ·ä½¿ç”¨ï¼Œå®ƒä¼šè‡ªåŠ¨å¤„ç† softmaxã€‚

**æ€»ç»“è®¾è®¡åŸåˆ™**

| æ¨¡å— | åŸå› /ä½œç”¨ |
| --- | --- |
| Conv + ReLU + Pool | æå–ç‰¹å¾ï¼Œé™ä½åˆ†è¾¨ç‡ |
| å¢åŠ é€šé“æ•° | æ•æ‰æ›´æ·±å±‚æ¬¡çš„æ¨¡å¼ |
| ReLU æ¿€æ´» | è®¡ç®—é«˜æ•ˆï¼Œé˜²æ¢¯åº¦æ¶ˆå¤± |
| æ± åŒ–æ“ä½œ | å‡å°‘è®¡ç®—ã€é²æ£’æ€§å¢å¼º |
| FC å±‚ | æ±‡æ€»ç‰¹å¾ï¼Œè¾“å‡ºç»“æœ |
| è¾“å‡ºç»´åº¦=2 | å¯¹åº”äºŒåˆ†ç±»é—®é¢˜ |

---

### `train.py`  - è®­ç»ƒæµç¨‹è®¾è®¡

```python
import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from dataset import CatDogDataset
from model import SimpleCNN
import torchvision.transforms as transforms
from tqdm import tqdm  

# ä½¿ç”¨ GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"å½“å‰ä½¿ç”¨è®¾å¤‡: {device}")

# å‚æ•°é…ç½®
EPOCHS = 10
BATCH_SIZE = 32
LR = 0.001
IMG_SIZE = 224
SAVE_PATH = 'best_model.pth'

# æ•°æ®é¢„å¤„ç†
train_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(),  
    # æ•°æ®å¢å¼ºï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œä»¥ 50% çš„æ¦‚ç‡ å°†å›¾åƒ æ°´å¹³ç¿»è½¬ï¼ˆå³å·¦å³å¯¹è°ƒï¼‰ã€‚
    # å¢åŠ æ ·æœ¬å¤šæ ·æ€§ï¼Œè®©æ¨¡å‹è§åˆ°æ›´å¤šâ€œä¸åŒè§’åº¦â€çš„æ•°æ®ï¼›æé«˜æ³›åŒ–èƒ½åŠ›ï¼Œå‡å°‘è¿‡æ‹Ÿåˆï¼Œå­¦åˆ°â€œçŒ«æ˜¯ä»€ä¹ˆâ€è€Œä¸æ˜¯â€œçŒ«æœå“ªè¾¹â€ï¼›æ¨¡æ‹Ÿç°å®åœºæ™¯	å®é™…æ‹æ‘„ä¸­ç‰©ä½“æ–¹å‘å¯èƒ½å·¦å³éƒ½æœ‰ï¼Œè®­ç»ƒé›†ä¸­æœªå¿…å…¨æœ‰è¦†ç›–
    # transforms.RandomHorizontalFlip(p=0.7)70% æ¦‚ç‡ç¿»è½¬ã€‚
    # åœ¨çŒ«ç‹—åˆ†ç±»ã€äººè„¸æ£€æµ‹ä¸­å¯ä»¥ç”¨ï¼Œä½†æ˜¯å«æœ‰æ–‡å­—ï¼Œæˆ–è€…æ–¹ä½ä¿¡æ¯é‡è¦çš„ï¼ˆé“è·¯åœºæ™¯ï¼‰ä¸èƒ½ç”¨ã€‚
    # è¿˜å¯ä»¥transforms.RandomRotation(10)æ—‹è½¬å¢å¼º
    transforms.ToTensor(), # æŠŠå›¾åƒä» [0, 255] æ˜ å°„åˆ° [0.0, 1.0]
    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3) 
    # æŠŠæ¯ä¸ªåƒç´ å€¼å½’ä¸€åŒ–åˆ°ä¸€ä¸ªç›¸å¯¹â€œæ ‡å‡†â€çš„åˆ†å¸ƒèŒƒå›´ï¼Œä¾¿äºç¥ç»ç½‘ç»œæ›´å¿«ã€æ›´ç¨³å®šåœ°è®­ç»ƒã€‚
])

test_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)
])

# åŠ è½½æ•°æ®
train_dataset = CatDogDataset(root_dir='data/train', transform=train_transform)
test_dataset = CatDogDataset(root_dir='data/test', transform=test_transform)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
# shuffle é˜²æ­¢æ¨¡å‹è®°ä½é¡ºåºï¼ˆæ¯”å¦‚è®­ç»ƒé›†å¦‚æœå‰åŠå…¨æ˜¯çŒ«ï¼ŒååŠå…¨æ˜¯ç‹—ï¼Œæ¨¡å‹å¯èƒ½å­¦åˆ°â€œé¡ºåºâ€ï¼Œè€Œä¸æ˜¯å›¾åƒç‰¹å¾ï¼‰ï¼Œæé«˜æ³›åŒ–èƒ½åŠ›ï¼ˆæ‰“ä¹±æ ·æœ¬åˆ†å¸ƒåï¼Œèƒ½æ›´å¥½åœ°é€¼è¿‘æ•´ä½“æ•°æ®çš„çœŸå®åˆ†å¸ƒï¼‰ï¼Œæå‡æ”¶æ•›ç¨³å®šæ€§ï¼ˆæ¯è½®è®­ç»ƒæ ·æœ¬é¡ºåºéƒ½ä¸ä¸€æ ·ï¼Œèƒ½é¿å…å±€éƒ¨æœ€å°å€¼æˆ–éœ‡è¡é—®é¢˜ï¼‰
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)
# æµ‹è¯•é›†æ˜¯ç”¨æ¥â€œè¯„ä¼°æ¨¡å‹æ•ˆæœâ€çš„ï¼Œå¿…é¡»ç¨³å®šã€å¯é‡å¤ã€‚å¦‚æœä½ åœ¨æµ‹è¯•æ—¶ä¹Ÿæ‰“ä¹±æ•°æ®é¡ºåºï¼Œä¼šå¯¼è‡´ï¼šæµ‹è¯•ç»“æœä¸ç¨³å®šï¼ˆæ¯æ¬¡æµ‹è¯•é¡ºåºå˜äº†ï¼‰ï¼›æ¨¡å‹å¯¹æ ·æœ¬çš„é¢„æµ‹é¡ºåºä¹Ÿå˜äº†ï¼Œéš¾ä»¥åšå‡†ç¡®ç‡ç­‰æŒ‡æ ‡å¯¹æ¯”ï¼›å¯è§†åŒ–ç»“æœæ— æ³•å¤ç°

# æ„å»ºæ¨¡å‹
model = SimpleCNN(num_classes=2).to(device)

# æŸå¤±å‡½æ•°ä¸ä¼˜åŒ–å™¨
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LR)
# ä¼˜åŒ–å™¨ï¼ˆOptimizerï¼‰å†³å®šäº†æ¨¡å‹å¦‚ä½•æ›´æ–°å‚æ•°ï¼Œè®©æŸå¤±å‡½æ•°å˜å°ï¼Œä»è€Œè®©æ¨¡å‹æ›´èªæ˜ã€‚ä¼˜åŒ–å™¨å°±æ˜¯æ ¹æ®æŸå¤±å‡½æ•°çš„æ¢¯åº¦ä¿¡æ¯ï¼Œå»æ›´æ–°æ¨¡å‹å‚æ•°ï¼ˆå¦‚æƒé‡å’Œåç½®ï¼‰ çš„ç®—æ³•ã€‚
# Adamè‡ªé€‚åº”å­¦ä¹ ç‡çš„ä¼˜åŒ–å™¨ï¼Œæ”¶æ•›å¿«ã€æ•ˆæœå¥½ï¼Œæœ€å¸¸ç”¨

# è®­ç»ƒå‡½æ•°
def train_one_epoch(model, loader, optimizer, criterion):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    pbar = tqdm(loader, desc='Training', leave=False) # è¿›åº¦æ¡è®¾ç½®
    for images, labels in pbar:
        images = images.to(device)
        labels = labels.to(device)

        optimizer.zero_grad() # æ¸…ç©ºä¹‹å‰æ®‹ç•™çš„æ¢¯åº¦å€¼ï¼Œé˜²æ­¢æ¢¯åº¦å†æ¬¡ç´¯åŠ ã€‚
        outputs = model(images) # æ­£å‘ä¼ æ’­
        loss = criterion(outputs, labels) # è®¡ç®—æŸå¤±
        loss.backward() # è®¡ç®—å½“å‰æ¢¯åº¦ï¼ˆåå‘ä¼ æ’­ï¼‰
        # åœ¨ PyTorch ä¸­ï¼Œæ¯æ¬¡ .backward() è®¡ç®—æ¢¯åº¦æ—¶ï¼Œé»˜è®¤æ˜¯å°†å½“å‰æ¢¯åº¦åŠ åˆ°å·²æœ‰æ¢¯åº¦ä¸Šï¼Œè€Œä¸æ˜¯æ›¿æ¢ã€‚
        optimizer.step() # ç”¨æ¢¯åº¦æ›´æ–°å‚æ•°

        # ç»Ÿè®¡
        running_loss += loss.item() * images.size(0) # å½“å‰ epoch ç´¯è®¡æŸå¤±æ€»å’Œ
        # loss.item()ï¼šå°†å½“å‰ batch çš„ loss ä» Tensor è½¬æˆ Python floatï¼ˆå¦åˆ™ä¸èƒ½ç´¯åŠ ï¼‰ã€‚images.size(0)ï¼šå½“å‰ batch ä¸­å›¾åƒçš„æ•°é‡ï¼ˆä¹Ÿå°±æ˜¯ batch_sizeï¼‰ã€‚ä¸ºä»€ä¹ˆä¹˜ä»¥ batch sizeï¼Ÿå› ä¸º loss æ˜¯å¯¹å½“å‰ batch çš„â€œå¹³å‡æŸå¤±â€ï¼Œæˆ‘ä»¬è¦æ¢å¤æˆâ€œæ€»æŸå¤±â€ï¼ˆæ€»å’Œï¼‰ï¼Œæ–¹ä¾¿æœ€åå¹³å‡
        _, predicted = torch.max(outputs, 1)
        # å–æ¯å¼ å›¾é¢„æµ‹ç»“æœä¸­æ¦‚ç‡æœ€å¤§çš„ç±»åˆ«ä½œä¸ºæœ€ç»ˆé¢„æµ‹ã€‚outputs æ˜¯æ¨¡å‹è¾“å‡ºçš„ logitsï¼ˆå½¢çŠ¶ï¼š[batch_size, num_classes]ï¼‰ã€‚è¿”å› (æœ€å¤§å€¼, ç´¢å¼•)ï¼Œæˆ‘ä»¬åªå…³å¿ƒç´¢å¼•ï¼Œå³ç±»åˆ«ç¼–å·ã€‚predicted æ˜¯å½¢çŠ¶ä¸º [batch_size] çš„é¢„æµ‹æ ‡ç­¾åˆ—è¡¨
        
        correct += (predicted == labels).sum().item()
        # ç»Ÿè®¡å½“å‰ batch ä¸­é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬ä¸ªæ•°ã€‚(predicted == labels) å¾—åˆ°ä¸€ä¸ªå¸ƒå°”å¼ é‡ï¼Œæ¯”å¦‚ [True, False, True]ã€‚.sum() å¯¹å¸ƒå°”å¼ é‡æ±‚å’Œï¼Œç›¸å½“äºç»Ÿè®¡æ­£ç¡®é¢„æµ‹ä¸ªæ•°ã€‚.item() æŠŠå¼ é‡è½¬æˆ Python æ•°å­—ï¼Œä¾¿äºåŠ åˆ° correct å˜é‡é‡Œ
        
        total += labels.size(0) # ç»Ÿè®¡è¿™ä¸ª batch çš„æ ·æœ¬æ•°ï¼ŒåŠ åˆ°æ€»æ•°ä¸­

        # æ›´æ–°è¿›åº¦æ¡
        pbar.set_postfix(loss=loss.item())

    epoch_loss = running_loss / total
    epoch_acc = correct / total
    return epoch_loss, epoch_acc

# éªŒè¯å‡½æ•°
def validate(model, loader, criterion):
    model.eval()
    running_loss = 0.0
    correct = 0
    total = 0

    pbar = tqdm(loader, desc='Validating', leave=False)
    with torch.no_grad(): # åœ¨ä¸éœ€è¦åå‘ä¼ æ’­çš„é˜¶æ®µï¼ˆå¦‚éªŒè¯ã€æµ‹è¯•ã€æ¨ç†ï¼‰ï¼Œå…³é—­ PyTorch çš„è‡ªåŠ¨æ±‚å¯¼æœºåˆ¶ï¼ŒèŠ‚çœå†…å­˜å’Œè®¡ç®—ã€‚
    # åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼šPyTorch ä¼šè‡ªåŠ¨æ„å»ºè®¡ç®—å›¾ï¼ˆcomputation graphï¼‰å¹¶ä¿å­˜æ‰€æœ‰ä¸­é—´å˜é‡ï¼ˆç”¨æ¥ .backward() åå‘ä¼ æ’­ï¼‰
    # åœ¨éªŒè¯æˆ–æµ‹è¯•æ—¶ï¼šæˆ‘ä»¬åªæ˜¯å‰å‘ä¼ æ’­ï¼ˆforwardï¼‰çœ‹æ¨¡å‹æ•ˆæœï¼Œä¸éœ€è¦è®¡ç®—æ¢¯åº¦ï¼Œä¹Ÿä¸ä¼šè°ƒç”¨ .backward()ã€‚
        for images, labels in pbar:
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            running_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

            pbar.set_postfix(loss=loss.item())

    epoch_loss = running_loss / total
    epoch_acc = correct / total
    return epoch_loss, epoch_acc

# è®­ç»ƒå¾ªç¯
best_val_acc = 0.0
for epoch in range(EPOCHS):
    print(f"\nEpoch {epoch+1}/{EPOCHS}")

    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)
    val_loss, val_acc = validate(model, test_loader, criterion)

    print(f"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | "
          f"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}")

    # ä¿å­˜æœ€ä½³æ¨¡å‹
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), SAVE_PATH)
        print(f"ä¿å­˜æ–°æ¨¡å‹ï¼š{SAVE_PATH}ï¼ŒéªŒè¯å‡†ç¡®ç‡æå‡ä¸º {val_acc:.4f}")

print("è®­ç»ƒå®Œæˆï¼æœ€ä½³éªŒè¯å‡†ç¡®ç‡ä¸ºï¼š", best_val_acc)
```

- é¢„å¤„ç†ä¸­å½’ä¸€åŒ–æ“ä½œå›å¯¹å›¾åƒçš„æ¯ä¸ªé€šé“ï¼ˆR/G/Bï¼‰ï¼ŒæŒ‰ä¸‹é¢å…¬å¼è¿›è¡Œå˜æ¢ï¼š
    
    $$
    \text{output} = \frac{\text{input} - \text{mean}}{\text{std}}
    $$
    
    å¯¹äº `[0.5, 0.5, 0.5]` æ¥è¯´å°±æ˜¯ï¼š
    
    $$
    \text{output} = \frac{\text{input} - 0.5}{0.5}
    $$
    
    ä¹Ÿå°±æ˜¯å°†åƒç´ å€¼ä» $0, 1$ æ˜ å°„åˆ° $-1, 1$ åŒºé—´ã€‚
    

---

### [`evaluate.py`](http://evaluate.py) - è¯„ä¼°ä¸å¯è§†åŒ–

- åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
- åœ¨éªŒè¯é›†è·‘ä¸€è½®ï¼Œè¾“å‡ºaccuracyå’Œæ··æ·†çŸ©é˜µ

```python
import os
import torch
import random
import matplotlib.pyplot as plt
import matplotlib
from torch.utils.data import DataLoader
from dataset import CatDogDataset
from model import SimpleCNN
import torchvision.transforms as transforms
from sklearn.metrics import classification_report

# è®¾ç½®è®¾å¤‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# å‚æ•°
BATCH_SIZE = 32
IMG_SIZE = 224
MODEL_PATH = 'best_model.pth'
NUM_VIS = 8  # å¯è§†åŒ–å›¾åƒæ•°

# ç±»åˆ«æ ‡ç­¾æ˜ å°„
idx_to_class = {0: 'cat', 1: 'dog'}

# æµ‹è¯•é›†é¢„å¤„ç†
test_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)
])

# åŠ è½½æµ‹è¯•é›†
test_dataset = CatDogDataset(root_dir='data/test', transform=test_transform)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)

# åŠ è½½æ¨¡å‹
model = SimpleCNN(num_classes=2).to(device)
model.load_state_dict(torch.load(MODEL_PATH, map_location=device))
model.eval()

# è¯„ä¼°å‡†ç¡®ç‡
correct = 0
total = 0
# classification report
all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels in test_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs, 1)

        correct += (predicted == labels).sum().item()
        total += labels.size(0)
        
        all_preds.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

acc = correct / total
print(f"Test Accuracy: {acc * 100:.2f}%")

# æ‰“å°åˆ†ç±»æŠ¥å‘Š
print("\n Classification Report:")
print(classification_report(all_labels, all_preds, target_names=['cat', 'dog']))

# å¯è§†åŒ–éƒ¨åˆ†é¢„æµ‹ç»“æœ
# åå½’ä¸€åŒ–å‡½æ•°ï¼ˆå°†[-1, 1]æ˜ å°„å›[0, 1]ï¼‰
def denormalize(tensor):
    return tensor * 0.5 + 0.5

# éšæœºæŒ‘é€‰æ ·æœ¬
sample_indices = random.sample(range(len(test_dataset)), NUM_VIS)

plt.figure(figsize=(16, 8))
for i, idx in enumerate(sample_indices):
    image, label = test_dataset[idx]
    input_tensor = image.unsqueeze(0).to(device) # æ¨¡å‹è¾“å…¥ shape = [batch_size, 3, 224, 224]ï¼Œæ‰€ä»¥åœ¨ç»´åº¦0çš„ä½ç½®å¢åŠ ä¸€ä¸ªç»´åº¦ï¼Œimage.shape = [3, 224, 224] å˜æˆ [1, 3, 224, 224]

    with torch.no_grad():
        output = model(input_tensor)
        _, pred = torch.max(output, 1)

    # è½¬æ¢ä¸ºå¯æ˜¾ç¤ºæ ¼å¼
    image_np = denormalize(image).permute(1, 2, 0).cpu().numpy()
    # .permute(1, 2, 0)ï¼ŒPyTorch çš„å›¾åƒå¼ é‡é»˜è®¤é¡ºåºæ˜¯ï¼š(C, H, W) = (é€šé“, é«˜, å®½)ã€‚è€Œ Matplotlib/NumPy çš„å›¾åƒæ ¼å¼æ˜¯ï¼š(H, W, C)ï¼Œæ‰€ä»¥ .permute(1, 2, 0) å°±æ˜¯äº¤æ¢ç»´åº¦ã€‚
    # matplotlib æ²¡æ³•ç›´æ¥è®¿é—®ï¼Œéœ€è¦å…ˆè½¬åˆ° CPU

    plt.subplot(2, NUM_VIS // 2, i + 1)
    plt.imshow(image_np)
    plt.axis('off')
    plt.title(f"Pred: {idx_to_class[pred.item()]}\nTrue: {idx_to_class[label]}", fontsize=12)

plt.tight_layout()
plt.savefig("prediction_visualization.png")
plt.show()
```

---

## å››ã€GitHubä¸å¼€æºè§„èŒƒæ•™å­¦

### GitåŸºç¡€æ“ä½œ

- `git init`ã€`git add .`ã€`git commit -m "msg"`
- `git remote add origin ...`ã€`git push`

---

## äº”ã€ResNet18ä¸è¿ç§»å­¦ä¹ çŸ¥è¯†ç‚¹

### ResNetç®€è¿°

- **ResNetï¼ˆæ®‹å·®ç½‘ç»œï¼‰** æ˜¯ä¸€ç§æ·±åº¦ç¥ç»ç½‘ç»œç»“æ„ï¼Œé€šè¿‡å¼•å…¥ **æ®‹å·®è¿æ¥ï¼ˆshortcut connectionï¼‰** è§£å†³æ·±å±‚ç½‘ç»œè®­ç»ƒä¸­çš„æ¢¯åº¦æ¶ˆå¤±å’Œæ€§èƒ½é€€åŒ–é—®é¢˜ã€‚
- ä¼ ç»Ÿæ·±å±‚ç½‘ç»œéšç€å±‚æ•°å¢åŠ ï¼Œå¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹æ•ˆæœä¸‹é™ï¼ˆé€€åŒ–ï¼‰ï¼ŒResNet é€šè¿‡è®©ç½‘ç»œå­¦ä¹ æ®‹å·®ï¼ˆå³è¾“å‡ºä¸è¾“å…¥çš„å·®å€¼ï¼‰ï¼Œå®ç°äº†â€œè·³è·ƒè¿æ¥â€ï¼Œä½¿å¾—ç½‘ç»œæ›´å®¹æ˜“ä¼˜åŒ–ã€‚
- æœ€åŸºç¡€çš„ç‰ˆæœ¬æ˜¯ **ResNet18**ï¼ŒåŒ…å« 18 å±‚æƒé‡å±‚ï¼Œç»“æ„ç®€å•ã€è®¡ç®—é‡è¾ƒå°ï¼Œé€‚åˆå…¥é—¨çº§ä»»åŠ¡æˆ–å°å‹æ•°æ®é›†å®éªŒã€‚å°½ç®¡å±‚æ•°ä¸é«˜ï¼Œä½†ç”±äºæ®‹å·®æœºåˆ¶çš„å¼•å…¥ï¼ŒResNet18 åœ¨è®¸å¤šä»»åŠ¡ä¸Šä¾ç„¶å…·æœ‰å¼ºå¤§çš„è¡¨ç°åŠ›ã€‚

### ä»€ä¹ˆæ˜¯é¢„è®­ç»ƒï¼Ÿ

- é¢„è®­ç»ƒæ¨¡å‹æ˜¯æŒ‡ï¼š**æ¨¡å‹åœ¨å¤§è§„æ¨¡æ•°æ®é›†ï¼ˆå¦‚ ImageNetï¼‰ä¸Šå·²ç»è®­ç»ƒå¥½**ï¼Œå…¶æå–çš„å›¾åƒç‰¹å¾å…·æœ‰å¾ˆå¼ºçš„é€šç”¨æ€§ï¼ˆå¦‚è¾¹ç¼˜ã€çº¹ç†ã€è½®å»“ç­‰åº•å±‚ç‰¹å¾ï¼‰ã€‚
- åœ¨æ–°ä»»åŠ¡ä¸Šï¼ˆæ¯”å¦‚çŒ«ç‹—åˆ†ç±»ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥ **åŠ è½½é¢„è®­ç»ƒæƒé‡**ï¼Œç„¶åï¼š
    - **å†»ç»“å·ç§¯å±‚ï¼Œä»…è®­ç»ƒåˆ†ç±»å¤´**ï¼Œé€‚åˆå°æ•°æ®é›†ï¼›
    - æˆ–è€…è¿›è¡Œ **å¾®è°ƒï¼ˆfine-tuningï¼‰**ï¼Œè®©æ¨¡å‹åœ¨æ–°ä»»åŠ¡ä¸Šè¿›ä¸€æ­¥ä¼˜åŒ–ã€‚
- é¢„è®­ç»ƒå¯ä»¥å¸®åŠ©æ¨¡å‹å¿«é€Ÿæ”¶æ•›ï¼Œå¹¶åœ¨æ•°æ®é‡è¾ƒå°‘çš„æƒ…å†µä¸‹è·å¾—æ›´å¥½çš„æ€§èƒ½ï¼Œæ˜¯ç°ä»£æ·±åº¦å­¦ä¹ ä¸­éå¸¸å¸¸è§ä¹Ÿéå¸¸æ¨èçš„åšæ³•ã€‚

### å¾®è°ƒæµç¨‹

- ä½¿ç”¨ `torchvision.models.resnet18(pretrained=True)` åŠ è½½ **ImageNet é¢„è®­ç»ƒæ¨¡å‹**ï¼›
- **æ›¿æ¢æœ€åçš„åˆ†ç±»å±‚**ï¼ˆåŸæ¥æ˜¯1000ç±» â†’ ç°åœ¨æ˜¯2ç±»ï¼‰ï¼›
- **å†»ç»“å‰é¢çš„å·ç§¯å±‚**ï¼Œåªè®­ç»ƒæœ€åçš„å…¨è¿æ¥å±‚ï¼ˆè¿™æ˜¯å…¸å‹çš„å¾®è°ƒæ–¹å¼ï¼‰ï¼›
- æ”¯æŒ GPU è®­ç»ƒï¼Œå¯ç”¨äºä½ çš„è®­ç»ƒæµç¨‹ä¸­ã€‚

```python
import torch
import torch.nn as nn
import torchvision.models as models

class FineTunedResNet18(nn.Module):
    """
    ä½¿ç”¨ImageNeté¢„è®­ç»ƒçš„ResNet18æ¨¡å‹è¿›è¡Œå¾®è°ƒ
    - å†»ç»“æ‰€æœ‰å·ç§¯å±‚
    - æ›¿æ¢æœ€åçš„åˆ†ç±»å±‚ä¸º2åˆ†ç±»
    """
    def __init__(self, num_classes=2, freeze_features=True):
        super(FineTunedResNet18, self).__init__()

        # åŠ è½½é¢„è®­ç»ƒçš„ ResNet18
        self.model = models.resnet18(pretrained=True)

        # æ˜¯å¦å†»ç»“ç‰¹å¾æå–éƒ¨åˆ†
        if freeze_features:
            for param in self.model.parameters(): #è¿”å›æ¨¡å‹ä¸­æ‰€æœ‰çš„å¯å­¦ä¹ å‚æ•°ï¼ˆé€šå¸¸æ˜¯æƒé‡ weight å’Œåç½® biasï¼‰ã€‚ä¹Ÿå°±æ˜¯ï¼šResNet18 çš„å·ç§¯å±‚ã€BNå±‚ã€å…¨è¿æ¥å±‚ç­‰çš„å‚æ•°åˆ—è¡¨ã€‚
                param.requires_grad = False

        # æ›¿æ¢æœ€åçš„å…¨è¿æ¥å±‚
        in_features = self.model.fc.in_features
        # è·å–åŸå§‹ fc å±‚çš„è¾“å…¥ç»´åº¦ï¼ˆé€šå¸¸ä¸º 512ï¼‰ï¼›è¿™ä¸ªå€¼ä¸å˜ï¼Œæˆ‘ä»¬ç”¨å®ƒæ¥æ„é€ ä¸€ä¸ªæ–°çš„è¾“å‡ºå±‚ã€‚
        self.model.fc = nn.Linear(in_features, num_classes)

    def forward(self, x):
        return self.model(x)
```

åœ¨ `train.py` ä¸ `evaluate.py` ä¸­æ›¿æ¢æ¨¡å‹éƒ¨åˆ†ï¼š

```python
# from model import SimpleCNN
from model import FineTunedResNet18
# åˆå§‹åŒ–å¾®è°ƒæ¨¡å‹ï¼ˆé»˜è®¤å†»ç»“ç‰¹å¾å±‚ï¼‰
model = FineTunedResNet18(num_classes=2, freeze_features=True).to(device)  
```

---

## å…­ã€å®ŒæˆREADME.md

# çŒ«ç‹—å›¾åƒäºŒåˆ†ç±»é¡¹ç›®

æœ¬é¡¹ç›®å®ç°äº†åŸºäº PyTorch çš„çŒ«ç‹—å›¾åƒäºŒåˆ†ç±»ç³»ç»Ÿï¼ŒåŒ…å«ä»æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€è¯„ä¼°å¯è§†åŒ–ç­‰å®Œæ•´æµç¨‹ã€‚æ”¯æŒè‡ªå®šä¹‰ CNN ä¸å¾®è°ƒçš„ ResNet18 ä¸¤ç§æ¨¡å‹ç»“æ„ï¼Œé€‚åˆè®¡ç®—æœºè§†è§‰åˆå­¦è€…ã€æ·±åº¦å­¦ä¹ è®­ç»ƒå®éªŒä¸è¿ç§»å­¦ä¹ å®è·µã€‚

---

## ğŸŒŸ é¡¹ç›®ç‰¹ç‚¹

- æ”¯æŒä¸¤ç§æ¨¡å‹ç»“æ„ï¼šç®€å•è‡ªå®šä¹‰ CNN å’Œ Fine-tuned ResNet18ï¼›
- é‡‡ç”¨æ ‡å‡†æ•°æ®ç»“æ„ `data_split/train`ã€`data_split/test`ï¼Œè‡ªåŠ¨åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†ï¼›
- é›†æˆæ•°æ®å¢å¼ºã€è®­ç»ƒå¯è§†åŒ–ã€å‡†ç¡®ç‡è¯„ä¼°ã€`sklearn` åˆ†ç±»æŠ¥å‘Šï¼›
- ä»£ç æ¨¡å—åŒ–æ¸…æ™°ï¼Œé€‚åˆæ•™å­¦ã€è¯¾ç¨‹è®¾è®¡æˆ–ä½œä¸ºæ·±åº¦å­¦ä¹ å…¥é—¨é¡¹ç›®æ¨¡æ¿ã€‚

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
project/
â”œâ”€â”€ dataset.py               # è‡ªå®šä¹‰ Dataset ç±»ï¼Œæ”¯æŒå¢å¼ºä¸åˆ’åˆ†
â”œâ”€â”€ model.py                 # åŒ…å« SimpleCNN å’Œ FineTunedResNet18 ä¸¤ç§æ¨¡å‹
â”œâ”€â”€ train.py                 # æ¨¡å‹è®­ç»ƒä¸»è„šæœ¬ï¼ˆå« tqdm å¯è§†åŒ–ï¼‰
â”œâ”€â”€ evaluate.py              # æµ‹è¯•æ¨¡å‹æ€§èƒ½ï¼Œåˆ†ç±»æŠ¥å‘Šä¸é¢„æµ‹ç»“æœå±•ç¤º
â”œâ”€â”€ data_split/              # å·²åˆ’åˆ†å¥½çš„è®­ç»ƒä¸æµ‹è¯•æ•°æ®é›†ï¼ˆcat/dogï¼‰
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ best_model.pth           # ä¿å­˜è®­ç»ƒä¸­è¡¨ç°æœ€å¥½çš„æ¨¡å‹å‚æ•°
â””â”€â”€ prediction_visualization.png  # æµ‹è¯•é›†ä¸­éƒ¨åˆ†é¢„æµ‹å›¾åƒå¯è§†åŒ–
```

---

## ğŸ”§ ç¯å¢ƒä¾èµ–

è¯·ä½¿ç”¨ Python 3.7+ ç‰ˆæœ¬ï¼Œå¹¶å»ºè®®ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒï¼ˆå¦‚ `venv` æˆ– `conda`ï¼‰ï¼š

```bash
pip install torch torchvision scikit-learn matplotlib tqdm
```

---

## ğŸ“¦ æ•°æ®å‡†å¤‡

è¯·å°†åŸå§‹çŒ«ç‹—æ•°æ®é›†æ”¾å…¥ `train/` æ–‡ä»¶å¤¹ä¸­ï¼Œå›¾åƒå‘½åæ ¼å¼å¦‚ä¸‹ï¼š

```
cat.0.jpg, cat.1.jpg, ..., dog.0.jpg, dog.1.jpg, ...
```

è¿è¡Œä»¥ä¸‹è„šæœ¬å®Œæˆæ•°æ®é€‰æ‹©ä¸åˆ’åˆ†ï¼š

```bash
python split_dataset.py  # ä½ å¯èƒ½å·²æœ‰è¿™éƒ¨åˆ†æ•°æ®åˆ’åˆ†ä»£ç 
```

åˆ’åˆ†åç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ cat/
â”‚   â””â”€â”€ dog/
â””â”€â”€ test/
    â”œâ”€â”€ cat/
    â””â”€â”€ dog/
```

---

## ğŸš€ æ¨¡å‹è®­ç»ƒ

é»˜è®¤ä½¿ç”¨ `SimpleCNN`ï¼š

```bash
python train.py
```

è‹¥è¦åˆ‡æ¢ä¸º ResNet18 å¾®è°ƒè®­ç»ƒï¼Œè¯·åœ¨ `train.py` ä¸­æ›¿æ¢æ¨¡å‹å¯¼å…¥ä¸åˆå§‹åŒ–ï¼š

```python
from model import FineTunedResNet18
model = FineTunedResNet18(num_classes=2, freeze_features=True).to(device)
```

---

## ğŸ“Š æ¨¡å‹è¯„ä¼°

è¿è¡Œæ¨¡å‹è¯„ä¼°ä¸åˆ†ç±»æŠ¥å‘Šç”Ÿæˆï¼š

```bash
python evaluate.p
```

æ§åˆ¶å°å°†è¾“å‡ºå¦‚ä¸‹ä¿¡æ¯ï¼š

```
Test Accuracy: 92.38%
Classification Report:
           precision    recall  f1-score   support
      cat       0.91      0.94      0.92       100
      dog       0.93      0.90      0.91       100
```

å¹¶ç”Ÿæˆ `prediction_visualization.png` æ–‡ä»¶ï¼Œå±•ç¤ºé¢„æµ‹æ•ˆæœã€‚

---

## ğŸ“Œ æ¨¡å‹åˆ‡æ¢è¯´æ˜

| æ¨¡å‹ç±»å‹ | æ¨¡å—ç±»å | ç‰¹ç‚¹ |
| --- | --- | --- |
| è‡ªå®šä¹‰ CNN | `SimpleCNN` | ç»“æ„ç®€å•ï¼Œé€‚åˆåˆå­¦è€… |
| é¢„è®­ç»ƒ ResNet18 | `FineTunedResNet18` | åˆ©ç”¨ ImageNet æƒé‡ï¼Œç²¾åº¦æ›´é«˜ï¼Œè®­ç»ƒæ›´å¿« |

---

## ğŸ“š æ¨èå­¦ä¹ è·¯å¾„

- ç†è§£å·ç§¯ç¥ç»ç½‘ç»œç»“æ„ï¼›
- å­¦ä¹  PyTorch ä¸­ Dataset / DataLoader / nn.Moduleï¼›
- æŒæ¡è¿ç§»å­¦ä¹ ä¸å¾®è°ƒç­–ç•¥ï¼›
- ç†Ÿæ‚‰æ¨¡å‹è®­ç»ƒæµç¨‹ä¸è¯„ä¼°æŒ‡æ ‡ï¼ˆAccuracyã€Precisionã€Recallã€F1ï¼‰ï¼›
- è¿›é˜¶å¯è§†åŒ–ä¸ TensorBoardã€æ··æ·†çŸ©é˜µç»˜åˆ¶ç­‰æŠ€å·§ã€‚

---

## ğŸ¤ è´¡çŒ®æ–¹å¼

æ¬¢è¿ä½ æäº¤ Issue æˆ– Pull Request è¿›è¡Œæ”¹è¿›å»ºè®®ã€æ¨¡å‹æ‰©å±•æˆ–é”™è¯¯ä¿®å¤ã€‚

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ª MIT å¼€æºåè®®ï¼Œè¯¦è§ LICENSE æ–‡ä»¶ã€‚

---

## ä¸ƒã€æ‰©å±•å»ºè®®

- æ·»åŠ  tensorboard å¯è§†åŒ–è®­ç»ƒæ—¥å¿—
- åŠ å…¥ EarlyStopping æå‰åœæ­¢
- å¼•å…¥æ··æ·†çŸ©é˜µç­‰è¾…åŠ©åˆ†æ
- åˆ¶ä½œ Gradio Demo å±•ç¤ºæ¨¡å‹é¢„æµ‹

ç•™ç»™å¤§å®¶è‡ªå·±å°è¯•å•¦ï¼